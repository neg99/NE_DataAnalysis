
\chapter{Проверка гипотез}
%Тут должно быть про определение критерия и построение его через статистику критерия.

\section{Общие сведения}

\subsection{Примеры гипотез}
Пусть $H_0$ --- это гипотеза (\textbf{h}ypothesis), т.е. некоторое предположение о случайной величине $\xi$, которое мы хотим проверить (модель --- это предположение, которое считается верным без проверки).
Она называется нулевой (null hypothesis), потому что позднее появится альтернативная к ней.

Важно, что гипотеза --- предположение о неизвестном законе распределения $\xi$, а не о выборке.

Например, гипотеза о том, что мат.ож. давления до и после приема лекарств одинаково. Или гипотеза о том, что распределение ошибки прибора нормальное, или о том, что распределение генератора псевдослучайных чисел равномерное на [0,1], или что . Или о том, что зависимости между временем на смотрением анимэ и успехами в учебе нет. Тут прослеживается такая особенность: в гипотезе обычно предполагается, что эффекта нет, так как решение принимается, если гипотеза отвергается.

\textbf{Задание 1}: Напишите, какую гипотезу вам было бы интересно проверить и какие данные для этого нужно было бы собрать?

\subsection{Критерий}
Для проверки гипотезы применяется критерий. Критерий --- это правило, по которому гипотеза либо отвергается, либо не отвергается. Про построение такого правила --- позже.

Правило строится на основе выборки. Разумное решение:
нам нужно построить правило, которое, как уже говорилось, показывает, насколько выборка отличается от тех предположений, которые постулируются в гипотезе. Если отличается сильно, то гипотеза отвергается.

Измерять отличие удобно в числах.
Поэтому вводится статистика критерия (функция от выборки, на основе которой строится критерий) $t=t(x_1,\ldots,x_n)$, которая выборке сопоставляет число.

Например, гипотеза про то, что $H_{0}:\E\xi=0$ (например, условия тренировки не влияют на результат (средняя разница в результатах нулевая)).
В этом случае, 0 --- ожидаемое значение (expected), выборочное среднее $\bar{x}$ --- наблюдаемое значение (observed). Их разница как раз измеряет отличие. Однако, просто по разнице не сказать, отличие большое или нет.
И вообще, числа могут получиться случайно, на их основе теорию не построить. Поэтому нужен статистический подход, который мы опишем ниже.

На основе результатов критерия принимают решения. Например, если лекарство показало эффективность (гипотезу о том, что оно неэффективно, отвергли), то его запускают в производство.

\subsection{Нет безошибочных решений}

Проблема: случайно может произойти что угодно, т.е. безошибочных решений практически не бывает. Приходится задавать максимальный уровень вероятности ошибки, на который можно согласиться при принятии решения.

Задаем маленький уровень значимости (significance level) $0<\alpha<1$ и соглашаемся, что с вероятностью $\alpha$ будем принимать неправильное решение.

Что такое маленький? Это зависит от критичности ошибки при принятии решения. Например, принять решение о полете и полететь на неисправном самолете или принять решение взять зонт и зря носить зонт в сумке весь день.

\textbf{Задание 2}: Придумайте ситуацию (гипотезу), когда она верна, а вы ошибочно считаете, что на не верна и поэтому принимаете неверное решение. В одном случае на вероятность ошибочного решение больше 0.001 вы бы точно не согласились.
Вторая ситуация --- когда согласились бы и на 0.2, но, пожалуй, не больше.

\subsection{Статистический критерий}
Чтобы построить теорию и отвечать на вопрос, маленькое или большое значение статистики критерия, отвергать гипотезу или нет, нужно перейти на теоретический язык.
Т.е., нужно рассматривать абстрактную выборку, `до эксперимента', где $x_i$ --- одинаково распределенные независимые случайные величины с тем же распределением, что и у $\xi$.

Таким образом, и статистика критерия $t=t(x_1,\ldots,x_n)$ --- тоже случайная величина.
Если верна $H_0$, то $t$ имеет некоторое распределение и принимает некоторый диапазон значений.

Например, для модели $\xi\sim N(a,\sigma^2)$ и гипотезы $H_{0}:\E\xi=0$, статистика критерия $t = \sqrt{n}\bar{x}/\sigma$ имеет распределение $N(0,1)$. Видим, что возможны любые значения. Однако, если мы допускаем некоторую вероятность ошибочно отвергнуть верную нулевую гипотезу, то критерий можем построить.
Обычно главное --- контролировать эту вероятность.

Разбиваем значения статистики критерия на две части, доверительную и критическую область так, что
вероятность для статистика критерия попасть в критическую область равна $\alpha$.

\textbf{Задание 3}. Нарисуйте плотность распределения статистики критерия $t=\sqrt{n}\bar{x}/\sigma$ при условии, что верна нулевая гипотезы, и разбейте область значений на две части, доверительную и критическую. Сделайте это разумным образом, чтобы было разумно значения из критической области считать не соответствующими справедливости нулевой гипотезы.

\paragraph{Формальное определение}
Назовем критерием разбиение области значений статистики критерия на две части, ${\Ascr}^{(\text{крит})}_\alpha$ и ${\Ascr}^{(\text{дов})}_\alpha$, такие что вероятность ошибки первого рода
$\alpha_I=\P_{H_0} (t\in {\Ascr}^{(\text{крит})}_\alpha) = \alpha$.

После того как критерий построен, пользуемся им уже в режиме `после эксперимента', когда выборка и значение статистики критерия --- числа. Если число $t$ попадает в критическую область, то гипотеза отвергается. Иначе --- не отвергается (но нельзя говорить, что принимается, это обсудим позднее).

Итак, важно (!): разбиение на доверительную и критическую область строится на теор. языке, для абстрактной выборки. А используется это разбиение уже для конкретной выборки, чисел.

Допустимо строить разбиение так, чтобы выполнялось $\alpha_I \leq \alpha$ (тогда критерий называется консервативным).

Часто удается построить только асимптотический критерий, когда $\alpha_I \rightarrow \alpha$ при $n\rightarrow \infty$. В этом случае критерий можно применять при достаточно (для критерия) большом объеме выборки, где допустимый объем выборки зависит от скорости сходимости.

Ниже более подробно.

\section{Схема построение критерия на основе статистики критерия}
%\paragraph{Схема построения критерия с помощью статистики критерия}
\begin{enumerate}
\item
Строим статистику критерия $t$ так, что:
\begin{itemize}
\item Cтатистика критерия $t$ должна измерять то, насколько выборка соответствует гипотезе.
В этом случае мы получаем значение статистики критерия для <<идеального соответствия>>.

Например, если гипотеза про математическое ожидание $H_{0}:\E\xi=a_{0}$, то $t=\bar{x}-a_{0}$ подходит под это требование.
Если гипотеза про дисперсию $H_{0}:\D\xi=\sigma^2_{0}$, то соответствие правильнее измерять отношением и поэтому подошло бы $t=s^2/\sigma^2_{0}$.

\begin{example*}
Пусть $H_{0}:\E\xi=a_{0}$; тогда $t=\bar{x}-a_{0}$ и <<идеальное
значение>> $t=0$.
\end{example*}
\item Распределение $t$ при верной $H_{0}$ должно быть известно хотя бы
асимптотически. Из-за этого часто преобразовывают меры несоответствия, приведенные выше.
Для $H_0:\, \E\xi = a_0$ в модели $\xi\sim N(a, \sigma^2)$ с известной дисперсией $\sigma^2$ удобно использовать статистику критерия $t=\sqrt{n}(\bar{\mathbf{x}}-a_{0})/\sigma \sim N(0,1)$.

Для $H_0:\, \D\xi = a_0$ в модели $\xi\sim N(a, \sigma^2)$ известно распределение статистики критерия $t=ns^2/\sigma^2_{0}\sim \chi^2_{n-1}$.
\end{itemize}

\item
Строим разбиение области значений статистики критерия $t$ так, что: %
\begin{itemize}
\item $\P(t\in \Ascr_\alpha^{\text{крит}} )= \alpha$.

\item Если альтернативная гипотеза $H_{1}$ (см. про нее в след.разделе) не конкретизирована, то $\Ascr_\a^{\text{(крит)}}$ следует выбрать
так, чтобы она располагалась как можно дальше от идеального значения.

\begin{example*}
Обозначения: pdf (probability distribution function) --- это плотность, а cdf (cumulative distribution function) --- это функция распределения.

В случае $t\sim\N(0,1)$ при идеальном значении $0$, разумно определить $\Ascr_\a^{\text{(крит)}}$
<<на хвостах>> графика плотности $\pdf_{\N(0,1)}$ симметрично по обе стороны
от 0 так, что для $\Ascr_\a^{\text{(крит)}}=(-\infty,-t_{\a})\cup(t_{\a},\infty)$
\[
\a/2=\int_{-\infty}^{-t_{\a}}\pdf_{\N(0,1)}(y)\d y=\int_{t_{\a}}^{+\infty}\pdf_{\N(0,1)}(y)\d y.
\]
 Иными словами,
\[
\a/2=1-\cdf_{\N(0,1)}(t_{1})\implies t_{1}=\cdf_{\N(0,1)}^{-1}(1-\a/2)
\]
и аналогично для $t_{0}$. Границы доверительной области часто называют критическими значениями.
\end{example*}
\item На будущее: если $H_{1}$ известна, то $\Ascr_\a^{\text{(крит)}}$ выбирается так,
чтобы максимизировать мощность критерия против альтернативы $H_{1}$, определения будут позже.
\end{itemize}
\end{enumerate}

\newpage
\subsection{Пример с числами}

Общая схема всех примеров будет как написано ниже.

\begin{itemize}
\item
Модель/предположения: (необязательно, но если есть, то это нужно проверять/обсуждать до использования критерия)

\item
Гипотеза: $H_0: ...$

\item
Статистика критерия $t = ...$:

\item
Ее распределение при условии, что верная $H_0$: ... --- выписано распределение. Если распределение асимптотическое, то при применении критерия нужно обращать внимание на объем выборки.

\item
Разбиение значений статистики критерия на доверительную и критическую области.

\item
Дана выборка, дан уровень значимости.

\item
Задание: проверить гипотезу, сказать, отвергается она или нет.
\end{itemize}

Как решать:
\begin{enumerate}
\item
Теор.часть, выборка абстрактная, уровень значимости $\alpha$ тоже произвольный. По виду статистики критерия вы понимаете, какое значение соответствует `идеальному' соответствию данных гипотезе. Рисуете график плотности статистики критерия и разбиваете значения на доверит. и крит. части, чтобы вероятность попасть в крит. область была равна $\alpha$. В крит.область включаете значения, наиболее далекие от `идеального'.

\item
Практическая часть, выборка состоит из чисел, уровень значимости --- конкретное число.
Подставляете в формулу статистики критерия числа, получаете число, обозначим $t_0$.
Затем считаем, чему равны критические значения (граница(ы) между критической и доверительной областями). Эти числа выражаются через обратную функцию распределения (это квантили). Значения можно вычислить  в R или Python, см. ниже приложение. Рисуем снова график плотности статистики критерия, отмечаем там найденные числа, показываем, где критическая область, где доверительная. На основе того, куда попало $t_0$, делаем вывод, отвергается или нет нулевая гипотеза.
\end{enumerate}

Ниже я буду давать три варианта, в зависимости от остатка деления дня рождения на 3.

\textbf{Задание 4}: Провести эту схему (записать то, что выше, с самого начала, со слова Модель) для уже разобранного выше критерия со статистикой критерия $t=\sqrt{n}(\bar{\mathbf{x}}-a_{0})/\sigma$. Там дисперсия $\sigma^2$ предполагается известной. Пусть она равна 1.44. Гипотеза: $H_0: \E\xi = a_0$, где (0) $a_0 =-1$, (1) $0.5$, (2) $1$. Примените критерий для выборки $(0,2,1,-1,-2)$ и уровня значимости (0) $\alpha = 0.05$, (1) $0.1$, (2)  $0.2$.

\textbf{Задание 5}: Провести эту схему для следующей постановки задачи.

Модель: $\xi$ имеет распределение Бернулли с неизвестным параметром, вероятностью успеха $p$. Напомню, что это означает, что она принимает значения 0 и 1, 1 (успех) с вероятностью $p$.

Гипотеза: $H_0: p=p_0$

Статистика критерия: \[
t=\sqrt{n}\frac{\hat{p}-p_{0}}{\sqrt{p_{0}(1-p_{0})}},
\]
где $\hat{p} = \bar{x}$, что логично, так как сумма значений выборки --- это в точности число успехов.

Ее распределение при условии, что $H_0$ верна: $t\tod\N(0,1)$ (т.е. это асимптотический критерий).

Дана выборка в виде: число успешных собеседований 45, неуспешных --- 55. Проверить гипотезу (0) $H_0: p = 0.45$, (1) $0.5$, (2) $0.4$, уровень значимости (0) $\alpha = 0.2$, (1) $0.05$, (2)  $0.1$.

Задание: проверить гипотезу, сказать, отвергается она или нет.


\textbf{Задание 6}: Провести эту схему для следующей постановки задачи.

Модель: нет (но предполагается, что $\xi$ принимает конечное число значений).

Гипотеза:
\[
H_{0}:\Pcal_\xi=\Pcal_{0},\text{ где }\Pcal_{0}:\begin{pmatrix}x_{1}^{*} & \dots & x_{k}^{*}\\
p_{1} & \dots & p_{k}
\end{pmatrix}.
\]

Статистика критерия: \[
T=\sum_{i=1}^{k}\frac{(n_{i}-np_{i})^{2}}{np_{i}}.
\]
Здесь такие обозначения: выборка $\mathbf{x}$ сгруппирована, т.е. каждому $x_{i}^{*}$ сопоставляем \emph{наблюдаемую}
абсолютную частоту $n_{i}$ (сколько раз оно встретилось в выборке); $np_{i}$ --- \emph{ожидаемая}
абсолютная частота.

Ее распределение при условии, что $H_0$ верна: $T\tod\chi^{2}(k-1)$.
 (т.е. это асимптотический критерий). По поводу свойств и вида плотности распределения хи-квадрат отсылаем к википедии \url{https://ru.wikipedia.org/wiki/%D0%A0%D0%B0%D1%81%D0%BF%D1%80%D0%B5%D0%B4%D0%B5%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5_%D1%85%D0%B8-%D0%BA%D0%B2%D0%B0%D0%B4%D1%80%D0%B0%D1%82}.

Дана выборка в виде: число успешных собеседований 45, неуспешных --- 55. Проверить гипотезу, что это распределение Бернулли с $p=0.5$. Проверить для значений $\alpha$ от 0.01 до 0.99 с шагом 0.01.

Задание: проверить гипотезу, сказать, отвергается она или нет. Когда надоест перебирать уровни значимости, найдите такое пороговое значение, называемое $p$-значение, что при меньших уровнях значимости гипотеза не отвергается, а при бОльших --- отвергается.

\section{Понятие вероятностного уровня $p$-value.}
\begin{defn*}
\emph{$p$-value} --- это такой значение, что при
значениях уровня значимости $\a$, больших $p$-value, $H_{0}$ отвергается (по причине
попадания $t$ в $\Ascr_\a^{\text{крит}}$), а при меньших --- не
отвергается.
\end{defn*}

$p$-value --- не вероятность, это пороговое значение. Неформально его можно интерпретировать как меру согласованности $H_{0}$ и выборки. Например, при больших значениях $p$-value практически при всех разумных уровнях значимости гипотеза не отвергается. При близких к нулю значениях $p$-value, наоборот, гипотеза будет отвергаться.

$p$-value --- максимальное значение уровня значимости, при котором гипотеза не отвергается (значение статистики критерия попадает в доверит. область). Или, что эквивалентно, минимальное значение уровня значимости, при котором гипотеза отвергается.

Если критическая область определяется через превышение статистики критерия некоторого значения $t_0$, то есть еще определение $p$-value как вероятности того, что при повторных экспериментах статистика критерия будет больше, чем значение в текущем эксперименте. Это определение написано и в wikipedia, но оно не универсальное. Тем не менее, лучше его знать.

\textbf{Задание 7} В заданиях 4, 5 и 6 найти p-value и сформулировать ответ в виде: при таких-то уровнях значимости гипотеза отвергается, при таких-то --- не отвергается.

\newpage
\section{Приложение. Вычисление функции распределения и обратной к ней}

\url{https://rdrr.io/snippets/}

По этому адресу можно делать вычисления он-лайн, вставив туда нужную часть кода

\begin{verbatim}
###normal distribution N(a, sd^2)
a <- 0
sd <- 1
x <- 2

#cumulative distribution function (cdf)
cdf <- pnorm(x, mean = a, sd = sd) print(cdf)

#inverse to this cdf
x <- qnorm(cdf, mean = a, sd = sd)
print(x)

###chi-square distribution chi2(m), where m is degree of freedom
x <- 240
m <- 200

#cumulative distribution function (cdf) of chi2(m)
cdf <- pchisq(x, df = m) print(cdf)

#inverse to this cdf
x <- qchisq(cdf, df = m)
print(x)
\end{verbatim}

Просто онлайн калькуляторы:\\
\url{https://planetcalc.ru/4986/}, \url{https://www.statdistributions.com/normal/} (для ф.р. нужен left tail) --- нормальное распределение,\\
\url{https://www.statdistributions.com/chisquare/} (для ф.р. нужен left tail) --- распределение хи-квадрат.

\section{Ошибки 1 и 2 рода. p-value}
\subsection{p-value}
\begin{enumerate}
\item	Повторяем про p-value для примера с хи-квадрат.
\item	Возвращаемся к гипотезе про мат.ож. Вопрос – как там посчитать p-value, если $t_0 = 1$?  Если $t_0 = -1.5$?
\item	 P-value – мера согласия данных с гипотезой. Минимальный уровень значимости, при котором гипотеза отвергается.
Проверили гипотезу, что производительность труда не зависит от вознаграждения. Получили p-value 0.01. Что это означает?
Значимость коэффициента корреляции. Гипотеза о том, что корреляция времени на дорогу в кафе и времени, проведенном в кафе, незначима. Получили p-value 0.8. Что это означает?
Задание: Проверяли много верных гипотез, каждый раз считали p-value. Какие p-value могли получиться? (приведите какие-нибудь 10)
\item	Т.о., p-value строится так, что если alpha>p, то гипотеза отвергается. Но чему должна быть равна вероятность того, что alpha>p ? Она должна быть равна alpha, по определению (вероятность отвергнуть H0, если она верна). P – функция от выборки, поэтому случайная величина. Получаем равномерное распределение.
Напомним, что ошибка 1 рода - ….  Для точного критерия она равна альфе. Нам важно понять, точный ли критерий? Возможны разные ситуации. Можно провести моделирование (случайное разыгрывание ситуации). Как оценивать вероятность?
Задание. 10 раз моделировали, получились такие p-value: 0.27, 0.34, 0.5, 0.7, 0.15, 0.65, 0.1, 0.55, 0.01, 0.45.  Постройте график эмпирической функции распределения p-value и скажите, можно ли пользоваться таким критерием?
А если 0.9, 0.25, 0.33, 0.5, 0.67, 0.11, 0.78, 0.44, 0.82, 0.99?
Пусть строят для своих 10 чисел.

Научить читать график распределения p-value. Консервативный и радикальный критерии.
Задание. Попросить нарисовать распределение p-value для этих случаев.
\end{enumerate}

\subsection{Ошибки 1 и 2 рода}
\begin{enumerate}
\item	Про ошибки 1 и 2 рода. Мощность, состоятельность. Показать картинку, объяснить, что на ней нарисовано.
\textbf{Задание}: найти ошибку 2 рода против альтернативы (указать ее), по вариантам.
Пусть дисперсия у всех 4, объем выборки 100.

(0) a0 = 1, a1 = 0.5\\
(1) a0 = -1, a1 = -1.2\\
(2) a0 = 0, a1 = 0.1\\
\item	Зависимость мощности от ….
\item	1 рода – контролируем, 2 рода – какая получится.
\item	Пример с самолетом.
\item	Если известно, с какой стороны альтернатива, то …

\item	Распределение p-value для нахождения мощности критерия. \textbf{Задание}. Предлагаю три графика. Характеризуйте критерий, точный, консервативны, радикальный. Маленькая мощность, большая мощность (рисую три пары картинок, причем радикальным нельзя пользоваться).

\item	FPTN и пр.
\end{enumerate}

