
\section{Базовая вероятность}
\begin{enumerate}
\item	Вы изучаете не числа, а закономерности. Числа – лишь появление этих закономерностей. Что такое закономерность в нашем случае? Мы рассматриваем окружающий мир как вероятностный, когда, в основном, не происходит что-то, что детерминированное (однозначное), а явления случайные, т.е. возможны разные исходы.
\item	Статистика: как по проявлениям вероятностной закономерности (вероятностной модели) узнать что-то про эту закономерность.
\item	Соответственно, нужно как-то формализовать эти объекты – вероятностные модели и их проявления (выборку).
\item	Итак, что такое вероятностная закономерность? Это вероятностное распределение (тут формулы). В дискретном случае – это состояния и вероятности. В непрерывном случае – плотность. Удобно говорить, что случайная величина имеет такое распределение, но это, скорее, формальность.
%\begin{teacher}
\item	\textbf{Задание}. Приведите пример таких закономерностей, которые неизвестны, но хотелось бы узнать? Вернее, вы предполагаете, что закономерность такая-то (такое-то распределение, непрерывное или дискретное), но хотели бы в этом убедиться. Подпишите ось x какими-то реальными числами, как вы себе представляете эту закономерность (плотность или дискретное распределение).
%\end{teacher}
\item	Пример – баллы за тест на экзамене (возможно, опустить). Вопрос – зависят ли результаты теста, если проверяющий знает, на каком числе баллов граница между оценками (пусть по пятибальной системе)?
\item	Итак, есть вероятностные распределения. Кстати, они необязательно одномерные. Нас интересуют какие-то их характеристики.
\item	Вер.пространство, Независимость - $\textsf{P}(AB) = \textsf{P}(A) \textsf{P}(B)$, несовместность - $\textsf{P}(AB) = 0$. Очевидно, что если множества не нулевой вероятности, но несовместные события не могут быть независимыми. Пусть есть две монеты, результаты -  $$\{(0,0), (0,1), (1,0), (1,1)\}.$$ Если ввести случайную величину, то можно говорить, что $\textsf{P}(\{(i,j)\}) = 1/4$.
\textbf{Задание}: Приведите два независимых (докажите) и два несовместных события в случае двух бросаний монеты (элементарное событие - пара чисел).
\item	Для примеров удобно пользоваться геометрическим определением равномерного распределения в области, когда вероятность пропорциональна размеру (длине, площади, объему) области. Я буду рисовать область, заштриховывая ее – имея в виду, что в этой области равномерное распределение. Можно говорить, что на квадрате задано равномерное распределение. А можно (удобно), что $(\xi,\eta) \in A)$. Пусть распределение в прямоугольнике.  На самом деле, штриховка означает  двумерную плотность $p(x,y)$. Т.е. представьте себе площадку над заштрихованной областью. $p(x,y) = c$, если $(x,y)$ лежит в заштихованной области, и 0 иначе. Так как площадь под графиком равна 1 ($\int \int p(x,y) = 0$), то константа равна 1, деленное на площадь заштрихованной области. Для равномерного распределения вероятность $A$ равна площади $A$, деленной на площадь все области (говорят: вероятность пропорциональна площади). Например, вероятность половины прямоугольника - это его площадь, делённая на всю площадь, т.е. 0.5.
\item	Очень важное понятие – это условные вероятности, они задают структуру того, что происходит.
Определение: $\textsf{P}(A\mid B) = \textsf{P}(AB)/ \textsf{P}(B)$. Если $A$ и $B$ независимы, то $\textsf{P}(A\mid B) = \textsf{P}(A)$. Условие сужает область, делает как бы перенормировку. От этого вероятность может как увеличиться, так и уменьшится.
\item 
 \textbf{Задание}. Что больше, вер-ть квадратика в круге или в полукруге? Нарисуйте такой квадратик, когда условная вероятность больше обычной и когда условная вероятность меньше оббычной.
\item	Формула полной вероятности Пусть дано вероятностное пространство $(\Omega,\mathcal{F},\mathbb{P})$, и полная группа попарно несовместных событий $\{B_i\}_{i=1}^{k} \subset \mathcal{F}$, таких что\\
$\forall i \; \mathbb{P} (B_i) > 0$;\\
$\forall{j \ne i} \; B_i \cap B_j = \varnothing$;\\
$\bigcup_{i=1}^k B_i=\Omega.$

Пусть $A \in \mathcal{F}$ --- интересующее нас событие. Тогда получим:
$$\mathbb{P}(A) = \sum\limits_{i=1}^{k} \mathbb{P}( A \mid B_i) \mathbb{P}(B_i).$$
Очень полезно для создания модели. Мы можем структурировать задачу, знаем, что на входе, и можем посчитать, что получается на выходе.
\item  Теорема Байеса. Мы знаем, что на выходе, а можем посчитать, что было на входе.
$$P(B_i \mid A) = \frac{P(A \mid B_i)\, P(B_i)}{P(A)} = \frac{P(A \mid B_i)\, P(B_i)}{\sum\limits_{i=1}^{k} \mathbb{P}( A \mid B_i) \mathbb{P}(B_i)}.$$
\item
\textbf{Задание} – пример про прибор, вероятность быть здоровым.\\
Пусть существует заболевание с частотой распространения среди населения 0,001 и метод диагностического обследования, который с вероятностью 0,9 выявляет больного, но при этом имеет вероятность 0,01 ложноположительного результата — ошибочного выявления заболевания у здорового человека. Найти вероятность того, что человек здоров, если он был признан больным при обследовании.

Обозначим событие, что обследование показало, что человек болен, как <<Б>> с кавычками, Б --- событие, что человек действительно больной, З --- событие, что человек действительно здоров. Тогда заданные условия переписываются следующим образом:
\begin{align*}P(\text{<<Б>>} \mid \text{Б}) &=0.9 \\
P(\text{<<Б>>} \mid \text{З}) &= 0.01 \\
P(\text{Б}) &= 0.001 \\
P(\text{З}) &= 1-P(\text{Б}), \text{значит}:
P(\text{З}) = 0.999 
\end{align*}

Вероятность того, что человек здоров, если он был признан больным равна условной вероятности:
\begin{align*}
P(\text{З} \mid \text{<<Б>>})
\end{align*}

Чтобы её найти, вычислим сначала полную вероятность признания больным:
\begin{align*}
P(\text{<<Б>>})&= P(\text{<<Б>>} \mid \text{З})\cdot P(\text{З})+P(\text{<<Б>>} \mid \text{Б})\cdot P(\text{Б}) \\ &= 0.01 \times 0.999 + 0.9 \times 0.001=0.01089
\end{align*}

Вероятность, что человек здоров при результате <<болен>>:
\begin{align*}
P(\text{З} \mid \text{<<Б>>}) &=
\frac
{P(\text{<<Б>>} \mid \text{З}) \cdot P(\text{З})}
{P(\text{<<Б>>})} \\ &=
\frac
{0.01 \times 0.999}
{0.01089}
\approx 0.917
\end{align*}

Таким образом, 91.7 \% людей, у которых обследование показало результат <<болен>>, на самом деле здоровые люди. Причина этого в том, что по условию задачи вероятность ложноположительного результата хоть и мала, но на порядок больше доли больных в обследуемой группе людей.

Если ошибочные результаты обследования можно считать случайными, то повторное обследование того же человека будет давать независимый от первого результат. В этом случае для уменьшения доли ложноположительных результатов имеет смысл провести повторное обследование людей, получивших результат <<болен>>. Вероятность того, что человек здоров после получения повторного результата <<болен>>, также можно вычислить по формуле Байеса:

\begin{gather*}
P\bigl((\text{З} \mid \text{<<Б>>}\bigr) \mid \text{<<Б>>})=\\=
\frac
{P(\text{<<Б>>} \mid \text{З}) \cdot \bigl(P(\text{<<Б>>} \mid \text{З}) \cdot P(\text{З})\bigr) }
{P(\text{<<Б>>} \mid \text{З}) \cdot \bigl(P(\text{<<Б>>} \mid \text{З}) \cdot P(\text{З}) \bigr) + P(\text{<<Б>>} \mid \text{Б}) \cdot \bigl( P(\text{<<Б>>} \mid \text{Б}) \cdot P(\text{Б}) \bigr) } =\\ =
\frac
{0.01 \times 0.01 \times 0.999}
{0.01 \times 0.01 \times 0.999 + 0.9 \times 0.9 \times 0.001}
\approx
0.1098
\end{gather*}

\end{enumerate} 